{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STT sample"
      ],
      "metadata": {
        "id": "QKjM2AC0t9rU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ses Kaydını Metne Çeviren Uygulama Örneği"
      ],
      "metadata": {
        "id": "tTOB8XVA8dpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: [openai/whisper-base](https://huggingface.co/openai/whisper-base)\n",
        "\n",
        "Dataset: [Nexdata/English_Emotional_Speech_Data_by_Microphone](https://huggingface.co/datasets/Nexdata/English_Emotional_Speech_Data_by_Microphone/viewer/default/train?views%5B%5D=train&row=0)"
      ],
      "metadata": {
        "id": "twJTUX1Ps_gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA durumu:\", torch.cuda.is_available())\n",
        "print(\"Kullanılan cihaz:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_nO7ghKpyuJ",
        "outputId": "695db681-cebe-4238-e36d-2075d67d59d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA durumu: True\n",
            "Kullanılan cihaz: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtCj-Cglnhb4",
        "outputId": "da019bfb-d832-4f1e-cca9-c628b6fc72b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=128a2857166c885eed25c4aa1666192197a37ff414ef29b1446dacae0e681593\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = whisper.load_model(\"base\", device=device)\n",
        "\n",
        "result = model.transcribe(\"/content/audio.wav\")\n",
        "print(result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8ZmuZn6p308",
        "outputId": "abd4eec8-b81c-4ea1-8eed-2d5fa1f16d0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " After the accident, Bill's sister is finally feeling better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mikrofonla Canlı Konuşmayı “Yaklaşık Gerçek Zamanlı” Metne Çeviren Uygulama Örneği"
      ],
      "metadata": {
        "id": "XrY3QtJuWnRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab (T4 GPU) üzerinde çalışacak, mikrofondan kısa parçalar (chunk) kaydeden ve bu parçaları “yaklaşık gerçek zamanlı” olarak metne çeviren bir örnek notebook kodu veriyorum. Adım adım çalıştır: her hücreyi sırayla çalıştır, sonra Start düğmesine bas ve konuş — her 2–4 saniyelik parça Colab’a gönderilip model tarafından anında transkribe edilecek ve birikimli transcript ekranda görünecek.\n",
        "\n",
        "Notlar / öneriler\n",
        "\n",
        "Colab’da GPU (T4) seçili olduğundan emin ol: Runtime → Change runtime type → Hardware accelerator: GPU.\n",
        "\n",
        "Daha düşük gecikme için kısa CHUNK_SECONDS (ör. 2–3) kullan. Model boyutu ile gecikme/kalite arasında takas var: tiny/base hızlı, small orta, medium/large daha doğru ama yavaş ve GPU belleği gerektirir.\n",
        "\n",
        "Bu örnek openai-whisper kullanır (local Whisper). Colab kurulumu biraz zaman alabilir."
      ],
      "metadata": {
        "id": "aPAVmiKUWvRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !! Çalıştırmadan önce runtime GPU seçili olsun !!\n",
        "# Kurulum (ffmpeg, whisper, soundfile)\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg\n",
        "!pip install -q -U openai-whisper soundfile\n",
        "\n",
        "# (isteğe bağlı) faster-whisper veya başka optimizasyonlar isterseniz buraya ekleyin.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkLdhEFtWqGQ",
        "outputId": "91ed5dcc-49ea-4d2e-e4f2-3f85e1b06237"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from google.colab import output\n",
        "import base64\n",
        "import io\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Ayarlar\n",
        "MODEL_NAME = \"small\"   # \"tiny\", \"base\", \"small\", \"medium\", \"large\" (bellek ve hız gereksinimi farklı)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CHUNK_SECONDS = 3      # her kayıt parçası kaç saniye olacak (2-4 iyi)\n",
        "LANG = None            # otomatik tanıma: None, belirli dil için \"tr\" gibi\n",
        "\n",
        "print(\"Cihaz:\", DEVICE, \" | Model:\", MODEL_NAME)\n",
        "\n",
        "# Modeli yükle (ilk yükleme biraz zaman alır)\n",
        "model = whisper.load_model(MODEL_NAME, device=DEVICE)\n",
        "\n",
        "# transcript biriktirme\n",
        "TRANSCRIPT = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7e-FusJWyky",
        "outputId": "6f15dcfa-130f-4033-b361-56847f2179ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cihaz: cuda  | Model: small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:08<00:00, 60.2MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "import base64\n",
        "\n",
        "RECORD_SECONDS = 5  # kaç saniye\n",
        "\n",
        "def record(sec=5, filename=\"audio.wav\"):\n",
        "    display(Javascript(f\"\"\"\n",
        "    async function record(sec) {{\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      let data = [];\n",
        "      recorder.ondataavailable = e => data.push(e.data);\n",
        "      recorder.start();\n",
        "\n",
        "      await new Promise(r => setTimeout(r, sec*1000));\n",
        "      recorder.stop();\n",
        "\n",
        "      await new Promise(r => recorder.onstop = r);\n",
        "      const blob = new Blob(data);\n",
        "      const arrayBuffer = await blob.arrayBuffer();\n",
        "      const base64String = btoa(\n",
        "          new Uint8Array(arrayBuffer)\n",
        "            .reduce((data, byte) => data + String.fromCharCode(byte), '')\n",
        "      );\n",
        "      google.colab.kernel.invokeFunction('notebook.save_audio', [base64String], {{}});\n",
        "    }}\n",
        "    record({sec});\n",
        "    \"\"\"))\n",
        "\n",
        "    # bu fonksiyon js içinden çağrılacak\n",
        "    def save_audio(b64):\n",
        "        audio_bytes = base64.b64decode(b64)\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(audio_bytes)\n",
        "        print(f\"Kayıt tamamlandı: {filename}\")\n",
        "    output.register_callback('notebook.save_audio', save_audio)\n"
      ],
      "metadata": {
        "id": "jabxEip3YG9D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record(10, \"kayit.wav\")  # 5 saniye kayıt yapar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8H-g4r22YI-4",
        "outputId": "ae418730-ce76-4579-d870-798a19d48b79"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function record(sec) {\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
              "      const recorder = new MediaRecorder(stream);\n",
              "      let data = [];\n",
              "      recorder.ondataavailable = e => data.push(e.data);\n",
              "      recorder.start();\n",
              "\n",
              "      await new Promise(r => setTimeout(r, sec*1000));\n",
              "      recorder.stop();\n",
              "\n",
              "      await new Promise(r => recorder.onstop = r);\n",
              "      const blob = new Blob(data);\n",
              "      const arrayBuffer = await blob.arrayBuffer();\n",
              "      const base64String = btoa(\n",
              "          new Uint8Array(arrayBuffer)\n",
              "            .reduce((data, byte) => data + String.fromCharCode(byte), '')\n",
              "      );\n",
              "      google.colab.kernel.invokeFunction('notebook.save_audio', [base64String], {});\n",
              "    }\n",
              "    record(10);\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kayıt tamamlandı: kayit.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = whisper.load_model(\"base\", device=device)\n",
        "\n",
        "result = model.transcribe(\"/content/kayit.wav\")\n",
        "print(result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THFSvZRDYylI",
        "outputId": "678e7302-542d-4b05-c081-853f834ef7d8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " How is it going?\n"
          ]
        }
      ]
    }
  ]
}